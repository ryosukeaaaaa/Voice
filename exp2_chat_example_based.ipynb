{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習２：用例ベース雑談システム\n",
    "\n",
    "概要\n",
    "* 用例ベース（検索ベース）の雑談対話システムを作成\n",
    "* 入力発話とシステム応答の候補との類似度計算には、SentenceBERTならびにコサイン類似度を使用\n",
    "\n",
    "目的\n",
    "* 「こう聞かれたら、こう答える」という一問一答型の音声対話システムの実装を体験する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記のような用例ベース対話システムを実装します。\n",
    "あらかじめ想定されるユーザ発話とそれに対応するシステム応答のペアを複数用意しておき、ユーザ発話が入力されたら最も近い想定ユーザ発話を検索します。\n",
    "そして、それに対応するシステム応答を出力します。\n",
    "類似度の計算には、SentenceBERTとコサイン距離を用います。\n",
    "\n",
    "<img src=\"./img/example.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインストール\n",
    "\n",
    "はじめに、必要となるライブラリをインストールします。ここではpipを使ってインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentenceBERT\n",
    "! pip install sentence-transformers\n",
    "! pip install fugashi\n",
    "! pip install ipadic\n",
    "\n",
    "# 音声認識\n",
    "! pip install pyaudio\n",
    "! pip install SpeechRecognition\n",
    "\n",
    "# 音声合成\n",
    "! pip install gTTS\n",
    "! pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 用例データの用意\n",
    "\n",
    "想定されるユーザ発話とそれに対応するシステム応答のペアデータ（用例データ）を読み込みます。\n",
    "データは data/example-base-data.csvに格納されており、各行が１つのペアデータ、１列目が想定ユーザ発話、２列目がシステム応答です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用例データを読み込む\n",
    "pair_data = []\n",
    "filename = './data/example-base-data.csv'\n",
    "print('Load from %s' % filename)\n",
    "with open(filename, 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        u1 = line.split(',')[0].strip()\n",
    "        u2 = line.split(',')[1].strip()\n",
    "        pair_data.append([u1, u2])\n",
    "        \n",
    "        print('%s -> %s' % (u1, u2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: SentenceBERTによる文ベクトル変換\n",
    "\n",
    "読み込んだ用例のデータのうち、想定ユーザ発話の各発話文をSentenceBERTを用いてベクトル化します。\n",
    "\n",
    "SentenceBERTのモデルには、今回は下記のものを用います。\n",
    "https://huggingface.co/sonoisa/sentence-bert-base-ja-mean-tokens-v2\n",
    "\n",
    "はじめに、上記のサイトを参考に、SentenceBERTを利用するためのクラスを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentenceBERTで使用\n",
    "from transformers import BertJapaneseTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Sentence-BERTの日本語版モデルを操作するためのクラス\n",
    "class SentenceBertJapanese:\n",
    "    \n",
    "    # コンストラクタ\n",
    "    # model_name_or_path: Sentence-BERTのモデル名またはパス\n",
    "    # device: 使用するデバイス（CPU or GPU）の指定。デフォルトでは利用可能な場合はGPUを使用。今回の演習ではCPUを想定する。\n",
    "    def __init__(self, model_name_or_path, device=None):\n",
    "        \n",
    "        # トークナイザの初期化\n",
    "        self.tokenizer = BertJapaneseTokenizer.from_pretrained(model_name_or_path)\n",
    "        \n",
    "        # モデルの初期化\n",
    "        self.model = BertModel.from_pretrained(model_name_or_path)\n",
    "        \n",
    "        # 推論モードにモデルを設定\n",
    "        self.model.eval()\n",
    "\n",
    "        # 使用するデバイスの設定\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        # モデルを指定したデバイスに移動\n",
    "        self.model.to(device)\n",
    "\n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "\n",
    "        # モデルの出力からトークンの埋め込みを取得\n",
    "        token_embeddings = model_output[0]\n",
    "        \n",
    "        # attention_maskをトークン埋め込みの次元に展開\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        \n",
    "        # トークンの埋め込みを平均プーリングして文の埋め込みを取得\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # 文のリストをベクトルに変換するメソッド\n",
    "    @torch.no_grad()\n",
    "    def encode(self, sentences, batch_size=8):\n",
    "        \n",
    "        all_embeddings = []\n",
    "        iterator = range(0, len(sentences), batch_size)\n",
    "        \n",
    "        for batch_idx in iterator:\n",
    "            \n",
    "            # 文をバッチ処理するための部分集合を取得\n",
    "            batch = sentences[batch_idx:batch_idx + batch_size]\n",
    "            \n",
    "            # 文をトークン化してモデル入力用にエンコード\n",
    "            encoded_input = self.tokenizer.batch_encode_plus(batch, padding=\"longest\", \n",
    "                                           truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "            \n",
    "            # モデルを使用してエンコードされた入力から出力を取得\n",
    "            model_output = self.model(**encoded_input)\n",
    "            \n",
    "            # 平均プーリングを使用して文の埋め込みを取得\n",
    "            sentence_embeddings = self._mean_pooling(model_output, encoded_input[\"attention_mask\"]).to('cpu')\n",
    "            \n",
    "            # 全ての文の埋め込みをリストに追加\n",
    "            all_embeddings.extend(sentence_embeddings)\n",
    "\n",
    "        # 最終的な文の埋め込みのテンソルを返す\n",
    "        return torch.stack(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentenceBERTを試してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sonoisa/sentence-bert-base-ja-mean-tokens-v2\"\n",
    "model = SentenceBertJapanese(MODEL_NAME)\n",
    "\n",
    "sentences = [\"京都大学へようこそ\", \"京都でおいしいごはんを食べた\"]\n",
    "sentence_embeddings = model.encode(sentences, batch_size=8)\n",
    "\n",
    "print(\"Sentence embeddings 1:\", sentence_embeddings[0])\n",
    "print(\"len(Sentence embeddings 1):\", len(sentence_embeddings[0]))\n",
    "      \n",
    "print(\"Sentence embeddings 2:\", sentence_embeddings[1])\n",
    "print(\"len(Sentence embeddings 2):\", len(sentence_embeddings[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のmodelを用いて、各用例データを文ベクトル化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用例データをSentence-BERTでベクトル化\n",
    "pair_data_vec = []\n",
    "for d in pair_data:\n",
    "    u1 = model.encode([d[0]])[0]\n",
    "    u2 = d[1]\n",
    "    pair_data_vec.append([u1, u2])\n",
    "    \n",
    "print(pair_data_vec[0][0])\n",
    "print(pair_data_vec[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 類似度計算\n",
    "\n",
    "次に、類似度を計算する関数を用意します。\n",
    "ここでは、入力ユーザ発話と、用例データを受け取り、入力ユーザ発話に最も類似するシステム応答を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コサイン類似度を計算する際にnumpyを使用\n",
    "import numpy as np\n",
    "\n",
    "# 類似度計算\n",
    "# input_sentence_vec: ベクトル化された入力ユーザ発話\n",
    "# pair_data_vec: ベクトル化された用例データ\n",
    "def matching(input_sentence_vec: np.array, pair_data_vec: list):\n",
    "    \n",
    "    # コサイン類似度が最も高いものを採用\n",
    "    cos_dist_max = 0.\n",
    "    response = None\n",
    "    \n",
    "    # 用例毎に処理\n",
    "    for pair_each in pair_data_vec:\n",
    "        \n",
    "        # コサイン類似度を計算\n",
    "        v1 = input_sentence_vec\n",
    "        v2 = pair_each[0]\n",
    "        cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "        \n",
    "        # 最大値を更新\n",
    "        if cos_dist_max < cos_sim:\n",
    "            cos_dist_max = cos_sim\n",
    "            response = pair_each[1]\n",
    "    \n",
    "    return response, cos_dist_max\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: テスト\n",
    "\n",
    "では、用例ベース対話システムをテストしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト\n",
    "\n",
    "# 入力発話　その１\n",
    "input_sentence = '趣味は何ですか'\n",
    "input_sentence_vec = model.encode([input_sentence])[0]\n",
    "\n",
    "response, cos_dist_max = matching(input_sentence_vec, pair_data_vec)\n",
    "\n",
    "print('入力：%s' % input_sentence)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)\n",
    "print()\n",
    "\n",
    "# 入力発話　その２\n",
    "input_sentence = '最近面白かったものは何ですか'\n",
    "input_sentence_vec = model.encode([input_sentence])[0]\n",
    "\n",
    "response, cos_dist_max = matching(input_sentence_vec, pair_data_vec)\n",
    "\n",
    "print('入力：%s' % input_sentence)\n",
    "print('応答：%s' % response)\n",
    "print('類似度：%.3f' % cos_dist_max)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: 音声対話システムとしての統合\n",
    "\n",
    "最後に、演習1で実装した方法を用いて、音声対話システムとして動作するように上記の機能を統合します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "\n",
    "# 音声認識を関数化\n",
    "def get_asr():\n",
    "    \n",
    "    r = sr.Recognizer()\n",
    "    r.pause_threshold = 0.5\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source) # 背景雑音へ適応する（１秒間）\n",
    "        print(\"どうぞ話してください >> \")\n",
    "        audio = r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        result = r.recognize_google(audio, language=\"ja-JP\")\n",
    "    except sr.UnknownValueError:\n",
    "        result = \"\"\n",
    "    except sr.RequestError as e:\n",
    "        result = \"\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 音声合成を関数化\n",
    "def play_tts(text):\n",
    "    \n",
    "    speech = gTTS(text=text, lang=\"ja\")\n",
    "\n",
    "    try:\n",
    "        speech.save(\"./data/test.mp3\")\n",
    "    except Exception as e:\n",
    "        print('ファイル保存エラー')\n",
    "    \n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(\"./data/test.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "\n",
    "    pygame.mixer.music.stop()\n",
    "    pygame.mixer.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 対話が終了状態に移るまで対話を続ける\n",
    "while True:\n",
    "    \n",
    "    # 音声入力＆音声認識\n",
    "    result_asr_utterance = get_asr()\n",
    "    print(\"ユーザ： \" + result_asr_utterance)\n",
    "    \n",
    "    # 「終了」がユーザ発話に含まれていれば対話を終了\n",
    "    if \"終了\" in result_asr_utterance:\n",
    "        break\n",
    "\n",
    "    # 用例を検索\n",
    "    input_sentence_vec = model.encode([result_asr_utterance])[0]\n",
    "    system_utterance, cos_dist_max = matching(input_sentence_vec, pair_data_vec)\n",
    "\n",
    "    print(\"システム： \" + system_utterance)\n",
    "    play_tts(system_utterance)\n",
    "    \n",
    "    print()\n",
    "\n",
    "# 対話終了\n",
    "print(\"対話終了\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a2eb5a09c124a414d0c803e7aaa7d348a03abaadc97f67347894a4c53feba33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
